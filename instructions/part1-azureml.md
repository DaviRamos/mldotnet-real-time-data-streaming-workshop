## Training your Machine Learning Model using Azure Machine Learning Service
ML.NET offers fantastic support to train your model using C# and offline. Training your model using ML.NET requires you however to have to manually set up your compute environment for larger machine learning models, and currently limits your from the possibility to train more complex neural networks. An alternative to ML.NET is to use Azure Machine Learning Service, which is Azure's managed machine learning environment. There are three ways to train your custom machine learning model in the service, using Azure's AutoML functionality, a visual interface or using Jupyter Notebooks with full support for custom models in Python or R. 

### Prerequisites
- Azure Machine Learning Service (please set up a data pipeline using the [following instructions](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/part2-streaming.md) first) 
- [Azure Storage Explorer](https://azure.microsoft.com/en-us/features/storage-explorer/)

Before we start to training our models, we will have to create a couple of compute targets that will be used throughout this section.

### Create compute targets
<details>
  <summary> Create compute targets </summary>
  <p>
    
1. Navigate to the Azure Machine Learning Service in Azure.
2. In the left menu, select **Compute**

![compute](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/images/azure-ml-compute-1.PNG)
3. Create a **Machine Learning Compute** according to the image below

![compute](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/images/azure-ml-compute-ml-1.PNG)
4. Create a **Kubernetes compute** according to the image below

![compute](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/images/azure-ml-compute-kubernetes-1.PNG)

</p>
</details>

### Visual Interface

<details>
  <summary> Steps to train your model using the Visual Interface </summary>
  <p>

- Navigate to the Azure Machine Learning Service in Azure.
- In the left menu, select "Visual Interface"
- Select "Launch visual interface"

This will open the Machine Learning workspace in which we can create experiments using a visual interface.
Feel free to navigate around to make yourself familiar with the surroundings. 

![Start](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/images/azure-ml-1.PNG)

#### Upload our data
The first thing we would like to do is to upload our data set. To this, click on the "New" button in the bottom-left corner. Select to "Upload from Local File"

![Start](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/images/azure-ml-2.PNG)

#### Create a new experiment
Once the dataset has been uploaded, click the "New" button once again and select to create a new "Blank Experiment"

![Start](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/images/azure-ml-3.PNG)

That should present you with the view below:
![Start](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/images/azure-ml-4.PNG)


### Setting up our experiment 
Use the left-most menu to set up our experiment. The visual interface functions such that you can drag and drop operations and connect them together in a training pipeline. 

The following operations are required
- The data source
- Select columns in data set (column indicies 1-10)
- Split Data (0.7 split)
- Two-Class Boosted Decision Tree (set the maximum number of leaves to 10 and the learning rate to 0.1)
- Train Model (set the label-column to isFraud)
- Score Model
- Evaluate Model

The experiment should eventually look like:
![Start](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/images/azure-ml-5.PNG)

### Running your experiment
To run your experiment, simply click **Run** in the bottom task bar and select our previously created compute target called **experiment**
Training the model will take about 15 min.

### Evaluate your model
Once training has completed, right click on the "Evaluate Model" step and click to Vizualize the Evaluation results
![Start](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/images/azure-ml-6.PNG)

We can see that our model generated by the Visual Interface have similar accuarcy as the one generated by ML.NET, but not the same quality in terms of precision and recall. 

### Deploy web service
To be able to integrate our ML model in to our data streaming pipeline, we would need to deploy it as a web service. 
To do so, please click the button **Create New Predictive Experiement** in the bottom right corner.

This will create a predictive experiment tab, with web inputs and outputs. To preapare the service for deployment, please click **Run**
This step will take about the same time to complete as the training step did.

![predictive](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/images/predictive-experiement-1.PNG)

Once building your web-service has completed, click **Deploy Web Service**

![predictive](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/images/predictive-experiement-2.PNG)

In the modal that appears, select the previously created compute **web-service** and click **Deploy**
![predictive](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/images/predictive-experiement-3.PNG)

</p>
</details>

### AutoML
<details>
  <summary> Steps to train your model using Azure AutoML </summary>
  <p>
    
Similiarly to ML.NET's AutoML functinality, Azure provides its own. This is a very neat functionality, as it allows you to get a jump start on training advanced model with little to no previous Machine Learning experience. 

### Upload our data
First thing we need to do before diving in to Azure AutoML is to upload our dataset to our storage account using the [Storage Explorer](https://azure.microsoft.com/en-us/features/storage-explorer/). There is a size limit uploading large files through the web interface, thus we have to reside to the storage explorer for our 450+ Mb file.  To do this, download and open the Azure Storage Explorer, navigate to your mlmodel storage account and upload the file to the container called model.

### Create a new experiement 

1. To create our first AutoML experiment, open the Azure Machine Learning Service in Azure and click on **Automated Machine Learning** to the left.

![automl1](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/images/azure-auto-ml-1.png)
    
2. Click **Create Experiment**
3. Enter an experiement name 
![automl1](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/images/azure-auto-ml-2.PNG)
4. Select the compute target named **experiment** previously created
5. Click **Next**
6. Select the storage account named **mlmodel**
7. Select the container named **model**
![automl1](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/images/azure-auto-ml-4.PNG)
8. Select the file data.csv which was uploaded in the previous step
9. Scroll down and select **isFraud** as the target column and classification as prediction task
![automl1](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/images/azure-auto-ml-5.PNG)
10. Expand the **Advanced Settings**
11. Set the training job time to 20 min and change the primary metric to norm_macro_recall
![automl1](https://github.com/aslotte/mldotnet-real-time-data-streaming-workshop/blob/master/instructions/images/azure-auto-ml-6.PNG)
12. Click **Start**

While this experiment is running, lets take a moment to reflect on why we changed primary metric from accuarcy to recall. If you remember earlier in this workshop, we discussed the fact that the data is highly unbalanced, meaning that if the algorithm just guesses non-fraudlent on everything it will achieve a 99.8% accuracy. Although accuracy is important for us, achieving a higher recall (minimum number of false negatives) is crucial.

  </p>
</details>  

### Jupyter Notebooks
<details>
  <summary> Steps to train your model using Jupyter Notebooks </summary>
  <p>
  </p>
</details>  

### Creating a Web-Service
