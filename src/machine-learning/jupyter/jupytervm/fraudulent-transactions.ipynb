{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraudulent Transactions - Training a classifier with Sklearn\n",
    "\n",
    "Welcome to this Jupyter Notebook in which we will train a simple classifier in Scikit Learn to detect fraudulent transactions. We will be exploring a number of libraries in Python to perform data exploration, data wrangling and data cleaning before feeding it in to a classifier of our liking. <br/>\n",
    "\n",
    "**Note**: Before running all cells in this notebook, enter your Azure information in step 10.\n",
    "\n",
    "Table of contents:\n",
    "1. Load\n",
    "2. Explore\n",
    "3. Transform\n",
    "4. Split the data\n",
    "5. Train our model\n",
    "6. Evaluate our model <br/>\n",
    "    a) Accuracy <br/>\n",
    "    b) Precision/Recall <br/>\n",
    "    c) Confusion matrix <br/>\n",
    "7. Iterate\n",
    "8. Persist our model\n",
    "9. Export to ONNX format <br/>\n",
    "10. Deployment <br/>\n",
    "11. Summary\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load \n",
    "To load the data, upload your dataset in the file explorer to the right and use <br/>\n",
    "pandas to load your dataset in to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Explore\n",
    "Use df.info to get an overview of the datatypes and size of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of dataset is: **6,362,620** rows with a total of **11 columns** <br/>\n",
    "The columns step, nameOrig and nameDest contains textual features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use df.head to take a quick look the values in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Find missing values\n",
    "We can use pandas isna (is not a number) method to determine if we have any missing values in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately for us we do not have any missing values to address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Transform\n",
    "Before we can start to work with our data, we need to transform it to a format an algorithm can understand<br/>\n",
    "\n",
    "Tranforming the data may include:\n",
    "- Replacing any missing values, infinity or NaN\n",
    "- Transforming textual features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 OneHotEncoding\n",
    "The **nameOrig** and **nameDest** columns contain string values which we need to transform to float vectors.\n",
    "But before we jump in to those columns, let's take a look at the **type** column. Given that this column has finitive options, we can use OneHotEncoding to transform the values to binary options.\n",
    "\n",
    "Pandas provide a very useful function for this, get_dummies.<br/> \n",
    "We can utilize this function to create new binary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['type'], prefix='type')], axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Label Encoder\n",
    "The nameOrig and nameDest columns contains a large number of permutations. OneHotEncoding could potentially create a very wide dataset, leading to out-of-memory exceptions, thus we can use something called label encoding instead to give each value a label.\n",
    "\n",
    "Given that a fraud generally can happen to anyone, we are going to assume that nameOrig does not matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "categorical_cols = [\"nameDest\"]\n",
    "df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 Plotting relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df, col=\"type\", hue=\"isFraud\")\n",
    "g.map(plt.scatter, \"amount\", \"step\", alpha=.7)\n",
    "g.add_legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df, col=\"type\", hue=\"isFraud\")\n",
    "g.map(plt.scatter, \"amount\", \"newbalanceDest\", alpha=.7)\n",
    "g.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly **newbalanceDest** and **amount** do not correlate as we expect for fraudulent cases. <br/> Many fraudulent cases appears to involve small amounts but also render the destination account with none or very little money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, seaborn as sns, numpy as np, pandas as pd, random\n",
    "from pylab import *\n",
    "from matplotlib.pyplot import plot, show, draw, figure, cm\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "fill_colors = ['#FF9999' if wt==1 else '#FFE888' for wt in list(df['isFraud'])]\n",
    "\n",
    "ax = Axes3D(fig) # Method 1\n",
    "\n",
    "ax.scatter(df['newbalanceDest'], df['oldbalanceDest'], df['amount'], c=fill_colors, marker='o')\n",
    "ax.set_xlabel('newBalanceDest')\n",
    "ax.set_ylabel('oldBalanceDest')\n",
    "ax.set_zlabel('Amount')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It surely seems like we may be able to create some kind of separation using these columns. Let's create variables holding the features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"amount\", \"newbalanceDest\", \"oldbalanceDest\", \"newbalanceOrig\", \"oldbalanceOrg\", \"nameDest\", \"type_CASH_IN\", \"type_CASH_OUT\", \"type_DEBIT\", \"type_PAYMENT\", \"type_TRANSFER\"]]\n",
    "Y = df[\"isFraud\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Split the data\n",
    "To evaluate the performance of the model, we will need a dataset for training and one for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Train our model\n",
    "Our data is now clean and in the correct format to be fed in to a machine learning algorithm.\n",
    "For this example we'll use an ensemble algorithm consisting of number of decision trees <br/>\n",
    "The random forest classifier will in our case create 100 decision trees, with a max depth of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.values.flatten()\n",
    "Y_test = Y_test.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Evaluate our model\n",
    "Before we can put our model to use, we'll need to know how good it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1 Accuracy\n",
    "We can use the classifers score() method with the test dataset to determine the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = clf.score(X_test, Y_test)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Not bad, an accuracy of **99.9%**! <br/> \n",
    "However, if you recall, our dataset was highly unbalanced and if we just guessed non-fraudulent for all transactions we would also achieve this accuracy. Are there any other metrics we can use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2 Precision-Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Precision**: High precision means that all transactions we flagged as fraudulent actually were (no false positives)\n",
    "- **Recall**: High recall means that we did not miss any fraudulent transactions (no false negatives)\n",
    "\n",
    "It's difficult to achieve a high value for both. In our case, it would make the most sense to have a high recall, as it is more important to not miss any fraudulent transactions than to flag a couple of non-fraudulent cases as fraudulent <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['non-fraudulent', 'fraudulent']\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "print(classification_report(Y_test,pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the report indicates, the precision is good for non-fraudulent cases.<br/> \n",
    "However, our **recall for fraudulent cases is 0**, meaning that we miss all fraudulent cases. \n",
    "Although we don't have any false positives, non of our customers fraudulent transactions are beight caught"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the precision-recall curve, we see that the curve is pushed against the left, when we actually want it towards the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Y_score = clf.predict_proba(X_test)\n",
    "Y_score = Y_score[:, 1]\n",
    "Y_score = Y_score.flatten()\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(Y_test, Y_score)\n",
    "\n",
    "plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "plt.plot(thresholds, recalls[:-1], \"g--\", label=\"Recall\")\n",
    "plt.legend(loc=\"center left\")\n",
    "plt.ylim([0, 1])\n",
    "plt.xlim([0, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3 Confusion matrix\n",
    "To further explore the ratio between false positives, false negatives, true positives and true negatives, we can have a look at the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "class_names =  ['Non-fraudulent', 'Fraudulent']\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(Y_test, pred, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix tells us that we marked all fraudulent cases as non-fraudulent, not great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Iterate\n",
    "So our model is far from great, let's see if we can improve it. \n",
    "One of the issues we are seeing right now is that despite it's accuracy, it is missing a lot of fraudulent transactions.\n",
    "A struggle we have is that our dataset is highly imbalanced. We can address this by weighing our inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our model again, but boosting our minority class, is fraudulent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_with_weights = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, class_weight=\"balanced\")\n",
    "clf_with_weights.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = clf_with_weights.score(X_test, Y_test)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuarcy dropped to **94.9%**, but let's see if we can outweight that with better recall-precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['non-fraudulent', 'fraudulent']\n",
    "\n",
    "pred_with_weights = clf_with_weights.predict(X_test)\n",
    "print(classification_report(Y_test, pred_with_weights, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! We can see that especially recall greatly increased for the fraudulent cases, meaning that we miss a lot less false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Y_score = clf_with_weights.predict_proba(X_test)\n",
    "Y_score = Y_score[:, 1]\n",
    "Y_score = Y_score.flatten()\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(Y_test, Y_score)\n",
    "\n",
    "plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "plt.plot(thresholds, recalls[:-1], \"g--\", label=\"Recall\")\n",
    "plt.legend(loc=\"center left\")\n",
    "plt.ylim([0, 1])\n",
    "plt.xlim([0, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrix\n",
    "Let's explore the confusion matrix for our new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(Y_test, pred_with_weights, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. Although not perfect we see that only 8% of fraudulent cases are missed and marked as non-fraudulent. Similarly we mark 5% as fraudulent while they are not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Persist our model\n",
    "There are multiple ways in which we can persist our trained model. \n",
    "Let's look at using both scikit learn as well as Azure's Python SDK to do so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(value=clf_with_weights, filename=\"fraudulent-classifier.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using Azure's Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "ws = Workspace.get(name=\"\", subscription_id='', resource_group='')\n",
    "model = Model.register(workspace=ws, model_path=\"fraudulent-classifier.pkl\", model_name=\"fraudulent-jupyter-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. ONNX Format\n",
    "The Open Neural Exchange Format (ONNX) allows models trained in different libraries to be loaded and used in others.\n",
    "ONNX is fully backed by Google, Facebook and Microsoft. Models trained in Python, e.g. using SciKitLearn or PyTorch can be exported to an ONNX format and imported and consumed by ML.NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "initial_type = [('float_input', FloatTensorType([1, X_train.shape[1]]))]\n",
    "onx = convert_sklearn(clf_with_weights, initial_types=initial_type)\n",
    "with open(\"fraudulent-classifier-jupyter.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Deployment \n",
    "The final piece is to deploy our model to production so that we can use it to make accurate predictions.\n",
    "To be able to deploy our model, we will first need to create a Docker image for deployment. The image requireses two components <br/>\n",
    "\n",
    "1. score.py -> loads the prediction engine\n",
    "2. conda.yml -> defines the requires dependencies\n",
    "\n",
    "The image can then be deployed to a running machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10.1 Image creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create conda file\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "fraudulentenv = CondaDependencies()\n",
    "fraudulentenv.add_conda_package(\"scikit-learn\")\n",
    " \n",
    "with open(\"fraudulentenv.yml\",\"w\") as f:\n",
    "    f.write(fraudulentenv.serialize_to_string())\n",
    "with open(\"fraudulentenv.yml\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # retrieve the path to the model file using the model name\n",
    "    model_path = Model.get_model_path('fraudulent-jupyter-model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "def run(raw_data):\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # make prbediction\n",
    "    y_hat = model.predict(data)\n",
    "    return json.dumps(y_hat.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10.2 Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tie altogether and create our Docker image as well as deploy it running service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "# configure the image\n",
    "image_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n",
    "                                                  runtime=\"python\", \n",
    "                                                  conda_file=\"fraudulentenv.yml\")\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"method\" : \"sklearn\"}, \n",
    "                                               description='Predict fraudulent transactions')\n",
    "\n",
    "service = Webservice.deploy_from_model(workspace=ws,\n",
    "                                       name='fraudulent-transactions-svc',\n",
    "                                       deployment_config=aciconfig,\n",
    "                                       models=[model],\n",
    "                                       image_config=image_config)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n",
    "\n",
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n",
    "                                                  runtime=\"python\", \n",
    "                                                  conda_file=\"fraudulentenv.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10.3 Predict\n",
    "To tie it altogheter, we can call our end-point with data to determine if this transaction is fraudulent or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST \\\n",
    "    -H 'Content-Type':'application/json' \\\n",
    "    -d '{\"data\": [[181.0, 0, 0, 0, 181.0, 439685, 0, 0, 0, 0, 1]]  }' \\\n",
    "    http://2f59f547-0890-44c4-a666-776e8ba9ce1b.southcentralus.azurecontainer.io/score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that we had to pass in already transformed data to our model. For real production use there are multiple ways we can go about this <br/>\n",
    "\n",
    "1. Create our own class to do pre-processing similar to what we did when we created the model\n",
    "2. Use Sklearn pipelines instead, build the transformation in to the pipeline and call pipeline.fit() on the incoming data before the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Summary\n",
    "This Notebook has demonstrated how you can build your own classifier using Python open-source libraries such as Pandas, ScikitLearn and Numpy in a Jupyter VM in Azure Machine Learning Service.\n",
    "As we can see, finding a good algorithm and fine-tunning its hyper-parameters can be complicated, but working with the notebook makes the work structured and easy to repeat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
